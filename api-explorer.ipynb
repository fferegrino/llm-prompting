{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3e458-b685-49f2-bf6d-688ea62df952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6606bd-fb48-4ed8-afb0-5168569f6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0.7 # Value between 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b4a08-79f5-4ab3-837e-7890f03859d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116ff4c-88b4-4602-ae40-2116c170b575",
   "metadata": {},
   "source": [
    "## The message structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329125d8-16e8-4f3d-b4fb-69cd3e2932fb",
   "metadata": {},
   "source": [
    "The way these models work is through a conversation interface, this conversation engine works through a series of messages in the format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"message\"\n",
    "}\n",
    "```\n",
    "\n",
    "As far as roles go, there are three:\n",
    "\n",
    " - \"user\"\n",
    " - \"assistant\"\n",
    " - \"system\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54811eb3-da57-422f-a91d-e15b1476401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    { \"role\": \"user\", \"content\": \"Who are you?\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b76d5-1386-48d9-86f9-82b1f8c1e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = client.chat.completions.create(\n",
    "    model = OPENAI_MODEL,\n",
    "    temperature = TEMPERATURE,\n",
    "    messages = messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97391fb0-a3a7-44f0-aa69-e8d1d525cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1726e16-ae7d-48ff-af90-99a68b857f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_choice = completions.choices[0]\n",
    "message_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bc7ce-7c68-4cb5-896f-ecb380957b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_choice.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2b479-a1b9-406d-8b68-3692fb555dc8",
   "metadata": {},
   "source": [
    "## The `system` role\n",
    "\n",
    "It is possible to use a *\"system\"* message to customise the assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19158aa7-3701-4b0c-ab1a-54f90dbf10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are Spaghetti Rigatoni, a high-cusine chef that is always preparing something tasty\"\n",
    "    },\n",
    "    { \"role\": \"user\", \"content\": \"Who are you?\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ceb09-7ff0-4ad3-af5d-0837577048b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = client.chat.completions.create(\n",
    "    model = OPENAI_MODEL,\n",
    "    temperature = TEMPERATURE,\n",
    "    messages = messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8defb92-1569-4c54-830c-8ec99f2ff0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c56487-40d3-4c9c-82c0-b63e3777d7d3",
   "metadata": {},
   "source": [
    "## A helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a004e-eb3b-4400-b696-501f876eb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0.1 # Value between 0 and 2\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_response(prompt):\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": prompt }\n",
    "    ]\n",
    "    completions = client.chat.completions.create(\n",
    "        model = OPENAI_MODEL,\n",
    "        temperature = TEMPERATURE,\n",
    "        messages = messages,\n",
    "    )\n",
    "    return completions.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffaa0c0-ebd6-419a-9386-03c606e2e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(\"Hello, my name is Antonio. Who are you?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960db74-24c2-40f3-b137-6bd7da474d5f",
   "metadata": {},
   "source": [
    "## A summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3e373-6412-45ab-8cee-a6fc84f75e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_star_review = \"\"\"\n",
    "Nice quick read with lots of ideas. \\\n",
    "I don't think you could possibly remember half of their \\\n",
    "guidelines even on the third read-through. Maybe that's just me, though. \\\n",
    "Quite possibly the most entertaining code book, but that's more due to \\\n",
    "the chapter-heading cartoons (a few of which were surprisingly funny) \\\n",
    "more than the text itself.\n",
    "One thing that was annoying was the authors' attempt to include examples \\\n",
    "from seemingly every language ever conceived. I knew the python, \\\n",
    "recognized some C, got totally lost in the javascript, and couldn't \\\n",
    "even identify some of the others. Would have been easier if they'd just \\\n",
    "picked a language and then supplemented others where necessary, instead of \\\n",
    "hopping around like a bee that can't pick a favorite flower.\n",
    "Still though, some good ideas and my code will be cleaner as I \\\n",
    "move forward now that I've read it. Solid three stars in the end.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730fef1-27bc-43f6-8456-d77af50af10d",
   "metadata": {},
   "source": [
    "### First attempt â€“ as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a928c82-af86-497b-835e-ce4200f760c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Summarize the text into a single sentence:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5a3cc-1b7d-4570-b6c1-4e710f5853e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_prompt = prompt + \" \" + three_star_review\n",
    "response = get_response(complete_prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4717844-9da3-4663-860a-624418014df7",
   "metadata": {},
   "source": [
    "### Second attempt - use delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbed83a-b4ee-4b84-945d-9738fd524fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summarize the text delimited by triple backticks into a single sentence.\n",
    "\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51576259-7ed3-4690-b2c4-bcbde98fdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_prompt = prompt.format(text=three_star_review)\n",
    "print(complete_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b1836-b23f-46d0-bae6-babf2de7927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(complete_prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a74816-ea7c-469e-8e78-d16167dea52e",
   "metadata": {},
   "source": [
    "### Third attempt - ask for structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e254ed6-470a-4f88-87de-b3e68ae6397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summarize the text delimited by triple backticks into a single sentence.\n",
    "Provide the response as a JSON object with the following keys: summary\n",
    "\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43407c13-30ee-41c3-b2c5-152a4577539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(text=three_star_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772211f-0916-4edb-b27c-e6ac5a17de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "resp = json.loads(response)\n",
    "\n",
    "resp['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa838e08-5bb1-4824-82f8-c20d5ada7dd4",
   "metadata": {},
   "source": [
    "### Fourth attempt - check for actual reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a16617-7d47-4ffc-839d-a5dea07bd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You will be provided with text delimited by triple backticks. \\\n",
    "If it contains a review about a book, summarize the text.\n",
    "\n",
    "If it does not contain a review about a book, simply write \\\"Not a book review\\\"\n",
    "\n",
    "Provide the response as a JSON object with the following keys: summary, is_a_review\n",
    "\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7f9dd-7af3-4c74-ade7-684591fe3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(text=three_star_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df4fcf-8d16-416c-a970-33366fff62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_a_review = \"\"\"Boxes and ingredients are packed in facilities that handles Peanut, Nuts, Sesame, Fish, \\\n",
    "Crustaceans, Milk, Egg, Mustard, Celery, Soya, Gluten and Sulphites. Due to the war in Ukraine, it has been \\\n",
    "necessary to substitute sunflower oil with rapeseed oil in some products without a label change. The FSA have \\\n",
    "advised that allergic reactions to rapeseed oil are rare.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae116e-3ff7-4a9f-a0dd-0f446f51509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(text=not_a_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec2142-3cef-4cb6-823d-53e9801406f4",
   "metadata": {},
   "source": [
    "### Fifth attempt - add more tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02a73d-913a-4f8d-a1d4-8327ed5d728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You will be provided with text delimited by triple backticks. \\\n",
    "If it contains a review about a book perform the following actions:\n",
    "\n",
    "1. Identify the sentiment â€“ sentiment\n",
    "2. Extract the keywords - keywords\n",
    "3. Summarize the review - summary\n",
    "4. Suggest a title for the review - title\n",
    "\n",
    "If it does not contain a review about a book, simply write \\\"Not a book review\\\"\n",
    "\n",
    "Provide the response as a JSON object with the following keys: summary, is_a_review, keywords, title, sentiment\n",
    "\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8cda3-b47d-4f15-961f-3a3cb84c2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(text=three_star_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140ab3f-2df3-4db4-ae55-c31a2fe37c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(text=not_a_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d405309-fd8a-46a5-9768-b3af487a3372",
   "metadata": {},
   "source": [
    "### Sixth attempt â€“ \"force it\" to return JSON\n",
    "\n",
    "#### Only available for `gpt-4-1106-preview`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26bbbb-e078-4629-a3bd-44192026a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_MODEL = \"gpt-4-1106-preview\"\n",
    "TEMPERATURE = 0.1 # Value between 0 and 2\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_response(prompt):\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": prompt }\n",
    "    ]\n",
    "    completions = client.chat.completions.create(\n",
    "        model = OPENAI_MODEL,\n",
    "        temperature = TEMPERATURE,\n",
    "        messages = messages,\n",
    "        \n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "\n",
    "    )\n",
    "    return completions.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7bb013-6833-4786-8e7f-5471f6b4ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(text=three_star_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418ddb6-c5ff-4bed-b29e-13de5196deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = json.loads(response)\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8aa167-d802-4329-b059-32e58dc246ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_response(\"Who are you?\")\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a475-c5fe-4d6d-8631-91459da59812",
   "metadata": {},
   "source": [
    "## Few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aaa5b3-2236-480f-9edf-78b285658cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0.1 # Value between 0 and 2\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_response(prompt):\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": prompt }\n",
    "    ]\n",
    "    completions = client.chat.completions.create(\n",
    "        model = OPENAI_MODEL,\n",
    "        temperature = TEMPERATURE,\n",
    "        messages = messages,\n",
    "    )\n",
    "    return completions.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226056e-09af-4c60-a2b4-e5f809512a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"I will give you a noun delimited by angle brackets, I want you to give a name for a specific instance of that noun.\n",
    "\n",
    ">>>\n",
    "{noun}\n",
    ">>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5edf8-ad5d-4d87-a5c5-9ada67ec0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aeiou\n",
    "# 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7e78d-dc16-404d-ae32-807e750cba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(noun='Egg'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7b972-f1ef-4365-a023-057c4889c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(noun='Train'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3675414-4197-4684-8ed3-d39933f7f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"I will give you a noun delimited by angle brackets, I want you to give a name for a specific instance of that noun.\n",
    "\n",
    "User: boat\n",
    "Assistant: Boaty McBoatface\n",
    "\n",
    "User: howitzer\n",
    "Assistant: Cannon McCannonface\n",
    "\n",
    "User: beer\n",
    "Assistant: Lager McLagerface\n",
    "\n",
    ">>>\n",
    "{noun}\n",
    ">>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74a9a7-7769-4d19-bc93-0f930135ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(noun='Egg'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6256a-fc1e-41f8-9f89-f99ebda96119",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(noun='Train'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe5efa-dcd9-469a-a110-c4962fe1848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(noun='snow plow'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7a55c-b31e-427f-90e6-572e5476a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt.format(noun='guimpe'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02814612-42ef-4844-a22e-055847b2caf5",
   "metadata": {},
   "source": [
    "## Tokens?\n",
    "\n",
    "Check out their documentation: https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195cd12-b55c-4ece-bf86-b6091c524b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d0729-ba14-4ad1-bb98-171fcbc7a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(OPENAI_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b035b2e-3bb3-453c-9316-0dcb817a2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encoding.encode(\"Hello, how are you doing?\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166bdf4-5901-4949-8c1f-3d193bdb90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = encoding.decode(tokens)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3140f1a7-c974-4051-99f5-b6eb86f2d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.decode_single_token_bytes(9906)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b8f9c-e168-4cdd-a193-a6f45aed4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.decode_single_token_bytes(9907)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b28d19-4a73-4cee-b9f9-5d5a8770a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.decode_single_token_bytes(9905)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35d7f9-c519-4f48-b7ed-dd4f99c21f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
